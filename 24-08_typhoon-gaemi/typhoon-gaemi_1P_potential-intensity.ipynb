{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute potential intensity\n",
    "\n",
    "```\n",
    "conda create -n potint -y netcdf4 xarray=0.16.2 numpy numba ipykernel                           # don't add matplotlib after xarray - broke installation\n",
    "conda activate potint\n",
    "pip install tcpypi\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel: potint\n",
    "import xarray as xr, os, glob, re\n",
    "from datetime import datetime\n",
    "import warnings; warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "\n",
    "from tcpyPI import pi\n",
    "from tcpyPI.utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMIP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/potential-intensity/\"\n",
    "\n",
    "# list models with available data\n",
    "mlist = list(set([fp.split(\"_\")[5] for fp in glob.glob(fpath+\"tos-rg/*.nc\") if not \"Veg\" in fp]))\n",
    "pi_list = list(set([re.sub(\".nc\",\"\",fp.split(\"_\")[-1]) for fp in glob.glob(fpath+\"pi/*.nc\") if not \"Veg\" in fp]))\n",
    "mlist = [m for m in mlist if not m in pi_list and not \"EC-Earth\" in m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlist# = [\"MIROC6\", \"CMCC-CM2-SR5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NESM3\n"
     ]
    }
   ],
   "source": [
    "for mdl in mlist:\n",
    "        \n",
    "    print(mdl)\n",
    "    \n",
    "    new_fnm = fpath+\"pi/pi_\"+mdl+\".nc\"\n",
    "    if os.path.exists(new_fnm): continue\n",
    "    \n",
    "    # load all the variables\n",
    "    tos = xr.concat([xr.open_dataset(fnm) for fnm in sorted(glob.glob(fpath+\"tos-rg/*_\"+mdl+\"*.nc\"))], \"time\")\n",
    "    hus,psl,ta = [xr.concat([xr.open_dataset(fnm) for fnm in sorted(glob.glob(fpath+varnm+\"/*_\"+mdl+\"*.nc\"))], \"time\") for varnm in [\"hus\",\"psl\",\"ta\"]]\n",
    "    \n",
    "    # merge into single DF\n",
    "    ds = xr.merge([tos, psl, ta, hus]).rename(plev = \"p\", ta = \"t\", hus = \"q\", psl = \"msl\")\n",
    "    \n",
    "    print(\"  Data loaded:   \"+datetime.now().time().strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    # calculate the potential intensity (may take a v long time - up to 3hrs for 200 years)\n",
    "    vmax, pmin, ifl, t0, otl = xr.apply_ufunc(\n",
    "        pi,\n",
    "        ds['sst'], ds['msl'], ds['p'], ds['t'], ds['q'],\n",
    "        kwargs=dict(CKCD=0.9, ascent_flag=0, diss_flag=1, ptop=50, miss_handle=1),  # used default value of CKCD = 0.9\n",
    "        input_core_dims=[\n",
    "            [], [], ['p', ], ['p', ], ['p', ],\n",
    "        ],\n",
    "        output_core_dims=[\n",
    "            [], [], [], [], []\n",
    "        ],\n",
    "        vectorize=True\n",
    "    )\n",
    "    \n",
    "    print(\"  PI calculated: \"+datetime.now().time().strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    # store the result in an xarray data structure\n",
    "    ds_out = xr.Dataset({\n",
    "        'vmax': vmax, \n",
    "        'pmin': pmin,\n",
    "        'ifl': ifl,\n",
    "        't0': t0,\n",
    "        'otl': otl,\n",
    "        })\n",
    "    \n",
    "    ds_out.to_netcdf(new_fnm)\n",
    "    \n",
    "    print(\"  Data saved:    \"+datetime.now().time().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For models saved at yearly resolution\n",
    "(takes too long to cat individual files together & run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = \"EC-Earth3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = sorted(glob.glob(fpath+\"tos-rg/*_\"+mdl+\"*.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18500101-18501231: complete\n",
      "18510101-18511231: "
     ]
    }
   ],
   "source": [
    "missing_years = []\n",
    "for fnm in fl:\n",
    "    \n",
    "    print(fnm[-20:-3], end = \": \")\n",
    "    new_fnm = fpath+\"pi/\"+mdl+\"/pi_\"+mdl+\"_\"+fnm[-20:]\n",
    "    if os.path.exists(new_fnm): \n",
    "        print(\"complete\")\n",
    "        continue\n",
    "        \n",
    "    tos = xr.open_dataset(fnm)\n",
    "    \n",
    "    if any([len(glob.glob(fpath+varnm+\"/*\"+fnm[-20:])) == 0 for varnm in [\"hus\", \"psl\", \"ta\"]]):\n",
    "        print(\"missing\")\n",
    "        missing_years.append(fnm[-20:])\n",
    "        continue\n",
    "    \n",
    "    hus, psl, ta = [xr.open_dataset(glob.glob(fpath+varnm+\"/*\"+fnm[-20:])[0]) for varnm in [\"hus\", \"psl\", \"ta\"]]\n",
    "    \n",
    "    # merge into single DF\n",
    "    ds = xr.merge([tos, psl, ta, hus]).rename(plev = \"p\", ta = \"t\", hus = \"q\", psl = \"msl\")\n",
    "    \n",
    "    # calculate the potential intensity (may take a v long time - up to 3hrs for 200 years)\n",
    "    vmax, pmin, ifl, t0, otl = xr.apply_ufunc(\n",
    "        pi,\n",
    "        ds['sst'], ds['msl'], ds['p'], ds['t'], ds['q'],\n",
    "        kwargs=dict(CKCD=0.9, ascent_flag=0, diss_flag=1, ptop=50, miss_handle=1),  # used default value of CKCD = 0.9\n",
    "        input_core_dims=[\n",
    "            [], [], ['p', ], ['p', ], ['p', ],\n",
    "        ],\n",
    "        output_core_dims=[\n",
    "            [], [], [], [], []\n",
    "        ],\n",
    "        vectorize=True\n",
    "    )\n",
    "    \n",
    "    # store the result in an xarray data structure\n",
    "    ds_out = xr.Dataset({\n",
    "        'vmax': vmax, \n",
    "        'pmin': pmin,\n",
    "        'ifl': ifl,\n",
    "        't0': t0,\n",
    "        'otl': otl,\n",
    "        })\n",
    "\n",
    "    ds_out.to_netcdf(new_fnm)\n",
    "    print(\"complete\")\n",
    "clear_output()\n",
    "print(\"Done.\")\n",
    "print(missing_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the individual files\n",
    "pi = xr.concat([xr.open_dataset(fnm) for fnm in sorted(glob.glob(fpath+\"pi/\"+mdl+\"/*.nc\"))], \"time\")\n",
    "pi.to_netcdf(fpath+\"pi/pi_\"+mdl+\".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"data/era5_pi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024\n"
     ]
    }
   ],
   "source": [
    "for y in [2024]:\n",
    "    print(y)\n",
    "    \n",
    "    new_fnm = fpath+\"pi_era5_\"+str(y)+\".nc\"\n",
    "    if os.path.exists(new_fnm): continue\n",
    "    \n",
    "    # load all the variables\n",
    "    sst,q,msl,t = [xr.open_dataset(fpath+varnm+\"-daily_era5_\"+str(y)+\".nc\") for varnm in [\"sst\",\"hus\",\"mslp\",\"ta\"]]\n",
    "    \n",
    "    # merge into single DF\n",
    "    ds = xr.merge([sst.sst, q.q, t.t, msl.msl]).rename(pressure_level = \"p\", latitude = \"lat\", longitude = \"lon\")\n",
    "\n",
    "    vmax, pmin, ifl, t0, otl = xr.apply_ufunc(\n",
    "        pi,\n",
    "        ds['sst'], ds['msl'], ds['p'], ds['t'], ds['q'],\n",
    "        kwargs=dict(CKCD=0.9, ascent_flag=0, diss_flag=1, ptop=50, miss_handle=1),  # used default value of CKCD = 0.9\n",
    "        input_core_dims=[\n",
    "            [], [], ['p', ], ['p', ], ['p', ],\n",
    "        ],\n",
    "        output_core_dims=[\n",
    "            [], [], [], [], []\n",
    "        ],\n",
    "        vectorize=True\n",
    "    )\n",
    "\n",
    "    # calculate the potential intensity (may take a v long time - up to 3hrs for 200 years)\n",
    "    vmax, pmin, ifl, t0, otl = xr.apply_ufunc(\n",
    "        pi,\n",
    "        ds['sst'], ds['msl'], ds['p'], ds['t'], ds['q'],\n",
    "        kwargs=dict(CKCD=0.9, ascent_flag=0, diss_flag=1, ptop=50, miss_handle=1),  # used default value of CKCD = 0.9\n",
    "        input_core_dims=[\n",
    "            [], [], ['p', ], ['p', ], ['p', ],\n",
    "        ],\n",
    "        output_core_dims=[\n",
    "            [], [], [], [], []\n",
    "        ],\n",
    "        vectorize=True\n",
    "    )\n",
    "    \n",
    "    # store the result in an xarray data structure\n",
    "    ds_out = xr.Dataset({\n",
    "        'vmax': vmax, \n",
    "        'pmin': pmin,\n",
    "        'ifl': ifl,\n",
    "        't0': t0,\n",
    "        'otl': otl,\n",
    "        })\n",
    "\n",
    "    ds_out.to_netcdf(new_fnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:potint]",
   "language": "python",
   "name": "conda-env-potint-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
