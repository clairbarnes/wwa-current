{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('/rds/general/user/cb2714/home/01_wwa/'); from wwa import *\n",
    "cproj = cartopy.crs.PlateCarree()\n",
    "\n",
    "xn, xx, yn, yx = [-85,-75,6,10]\n",
    "Xn, Xx, Yn, Yx = [-85,-75,5,15]\n",
    "\n",
    "units = {\"pr\" : \"mm/day\", \"tasmin\" : \"degC\", \"tasmax\" : \"degC\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# **Observational datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **Compile CHIRPS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(\"../00_WWA_project_folder/live/data/chirps_05/*.nc\").sel(longitude = slice(xn,xx), latitude = slice(yn, yx))\n",
    "ds.to_netcdf(\"data/chirps05_panama.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Compile MSWEP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n"
     ]
    }
   ],
   "source": [
    "# cut out yearly slices\n",
    "for y in range(2023, 1978, -1):\n",
    "    \n",
    "    new_fnm = \"mswep/mswep_panama_\"+str(y)+\".nc\"\n",
    "    if os.path.exists(new_fnm): continue\n",
    "    \n",
    "    print(y)\n",
    "    da = xr.open_mfdataset(\"../00_WWA_project_folder/live/data/mswep_*/\"+str(y)+\"*.nc\").sel(lon = slice(xn,xx), lat = slice(yx, yn))\n",
    "    wrap_lon(da).rename(precipitation = \"pr\").to_netcdf(new_fnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile into single file\n",
    "xr.open_mfdataset(\"mswep/mswep_panama_*.nc\").to_netcdf(\"data/mswep_panama.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MSWX tmax & tmin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n"
     ]
    }
   ],
   "source": [
    "varnm = \"tmin\"\n",
    "\n",
    "# cut out yearly slices\n",
    "for y in range(2023, 1978, -1):\n",
    "    \n",
    "    new_fnm = \"mswep/mswx_\"+varnm+\"_panama_\"+str(y)+\".nc\"\n",
    "    if os.path.exists(new_fnm): continue\n",
    "    \n",
    "    print(y)\n",
    "    da = xr.open_mfdataset(\"../00_WWA_project_folder/live/data/mswx/\"+varnm+\"_*/\"+str(y)+\"*.nc\").sel(lon = slice(xn,xx), lat = slice(yx, yn))\n",
    "    wrap_lon(da).rename(air_temperature = varnm).to_netcdf(new_fnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile into single file\n",
    "xr.open_mfdataset(\"mswep/mswx_\"+varnm+\"_panama_*.nc\").to_netcdf(\"data/mswx_\"+varnm+\"_panama.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **ERA5land**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Download**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "for y in [str(y) for y in range(2023,1950,-1)]:\n",
    "#     for m in [str(m).rjust(2, \"0\") for m in range(13)[1:]]:\n",
    "        \n",
    "        new_fnm = 'era5-land/era5land_panama_tp_'+y+'.nc'\n",
    "        if os.path.exists(new_fnm): continue\n",
    "        print(new_fnm)\n",
    "\n",
    "        c.retrieve(\n",
    "            'reanalysis-era5-land',\n",
    "            {\n",
    "                'variable': [\n",
    "                    'total_precipitation',\n",
    "                ],\n",
    "                'year': y,\n",
    "                'month': [\n",
    "                    '01', '02', '03',\n",
    "                    '04', '05', '06',\n",
    "                    '07', '08', '09',\n",
    "                    '10', '11', '12'],\n",
    "                'day': [\n",
    "                    '01', '02', '03',\n",
    "                    '04', '05', '06',\n",
    "                    '07', '08', '09',\n",
    "                    '10', '11', '12',\n",
    "                    '13', '14', '15',\n",
    "                    '16', '17', '18',\n",
    "                    '19', '20', '21',\n",
    "                    '22', '23', '24',\n",
    "                    '25', '26', '27',\n",
    "                    '28', '29', '30', '31',\n",
    "                ],\n",
    "                'time': [\n",
    "                    '00:00', '01:00', '02:00',\n",
    "                    '03:00', '04:00', '05:00',\n",
    "                    '06:00', '07:00', '08:00',\n",
    "                    '09:00', '10:00', '11:00',\n",
    "                    '12:00', '13:00', '14:00',\n",
    "                    '15:00', '16:00', '17:00',\n",
    "                    '18:00', '19:00', '20:00',\n",
    "                    '21:00', '22:00', '23:00',\n",
    "                ],\n",
    "                'area': [\n",
    "                    9.7, -80.25, 8.7,\n",
    "                    -79.25,\n",
    "                ],\n",
    "                'format': 'netcdf',\n",
    "            },\n",
    "            new_fnm)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Compile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset([fnm for fnm in glob.glob(\"era5-land/*.nc\")]).max(\"expver\").tp\n",
    "ds = ds.resample(time = \"D\").sum()\n",
    "ds.to_netcdf(\"data/era5land_panama.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# **Climate models - extract data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **HighResMIP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extract subset of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list & filter models\n",
    "synda_path = \"/rds/general/project/wwa/ephemeral/synda_clair/data/HighResMIP/\"\n",
    "out_path = \"/rds/general/user/cb2714/home/01_wwa/24-01_Panama-drought/highresmip/tmp/\"\n",
    "\n",
    "mdl_list = {varnm : list() for varnm in [\"pr\", \"tasmin\", \"tasmax\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "for fp in glob.glob(synda_path+\"*/r1i1*\"):\n",
    "    print(\"_\".join(fp.split(\"/\")[-2:]))\n",
    "    \n",
    "    for varnm in list(mdl_list.keys()):\n",
    "        \n",
    "        fl = sorted(glob.glob(fp+\"/\"+varnm+\"_*.nc\"))\n",
    "        print(\"  \"+varnm+\" (\"+str(len(fl))+\") \", end = \"\")\n",
    "        \n",
    "        if len(fl) == 0: \n",
    "            print(\"No data\")\n",
    "            continue\n",
    "            \n",
    "        # filter to remove any runs that don't cover the required period\n",
    "        if min([fnm[-20:-16] for fnm in fl]) > \"1980\" or max([fnm[-11:-7] for fnm in fl]) < \"2023\": \n",
    "            print(str(min([fnm[-20:-16] for fnm in fl]))+\"-\"+str(max([fnm[-11:-7] for fnm in fl]))+\" only\")\n",
    "            continue\n",
    "            \n",
    "        print(\"KEEP\")\n",
    "        mdl_list[varnm].append(fp)\n",
    "      \n",
    "    print(\"\")\n",
    "clear_output(wait = False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# extract subset of data for easier handling\n",
    "for varnm in mdl_list.keys():\n",
    "    ml = mdl_list[varnm]\n",
    "    \n",
    "    for fp in ml:\n",
    "        print(fp.split(\"/\")[-2] + \" (\"+str(ml.index(fp)+1)+\"/\"+str(len(ml))+\")\")\n",
    "        \n",
    "        fl = sorted(glob.glob(fp+\"/\"+varnm+\"_*.nc\"))\n",
    "        print(\"  \"+varnm+\" (\"+str(len(fl))+\") \", end = \"\")\n",
    "        \n",
    "        for fnm in fl:\n",
    "        \n",
    "            new_fnm = out_path + re.sub(\"-present\", \"\", re.sub(\"-future\", \"\", fnm.split(\"/\")[-1]))\n",
    "            if os.path.exists(new_fnm): continue\n",
    "                \n",
    "            # if not already done, load the data & cut out the required region\n",
    "            da = wrap_lon(convert_units_to(xr.open_dataset(fnm)[varnm].reset_coords(drop = True), units[varnm]))\n",
    "            \n",
    "            # fix dimension names if necessary\n",
    "            if \"longitude\" in da.coords: da = da.rename(longitude = \"lon\", latitude = \"lat\")\n",
    "            \n",
    "            # save daily data over slightly larger region\n",
    "            box = np.logical_and(np.logical_and(da.lon >= Xn, da.lon <= Xx), np.logical_and(da.lat >= Yn, da.lat <= Yx))\n",
    "            box = box.where(box == 1).dropna(\"lon\", \"all\").dropna(\"lat\", \"all\")\n",
    "            sp = da.sel({\"lon\" : box.lon, \"lat\" : box.lat})\n",
    "            sp.to_netcdf(new_fnm)\n",
    "            \n",
    "            print(\".\", end = \"\")\n",
    "\n",
    "        print(\"\")\n",
    "    clear_output(wait = False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Compile into single dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **CMIP6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **CORDEX (SAM)**\n",
    "_Downloaded via synda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "synda_path = \"/rds/general/project/wwa/ephemeral/synda_clair/data/\"\n",
    "out_path = \"/rds/general/user/cb2714/home/01_wwa/24-01_Panama-drought/cordex/tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any models that don't have both historical & rcp85\n",
    "model_list = [m for m in sorted(glob.glob(synda_path+\"*/*/*\")) if not \"HighResMIP\" in m and not \"CMIP6\" in m]\n",
    "\n",
    "mdl_list = {k : list() for k in [\"pr\", \"tasmin\", \"tasmax\"]}\n",
    "for fp in model_list:\n",
    "    for varnm in ml.keys():\n",
    "        fl_hist = glob.glob(fp+\"/\"+varnm+\"/*hist*.nc\")\n",
    "        fl_rcp = glob.glob(fp+\"/\"+varnm+\"/*rcp85*.nc\")\n",
    "        \n",
    "        if len(fl_hist) == 0 or len(fl_rcp) == 0: continue\n",
    "        mdl_list[varnm].append(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "abridge_gcm = {'CCCma-CanESM2' : \"CanESM2\",\n",
    "               \"CNRM-CERFACS-CNRM-CM5\" : \"CNRM-CM5\",\n",
    "               'CSIRO-QCCCE-CSIRO-Mk3-6-0' : 'CSIRO-Mk3-6-0',\n",
    "               \"ICHEC-EC-EARTH\" : \"EC-EARTH\",\n",
    "               'IPSL-IPSL-CM5A-LR' : 'IPSL-CM5A-LR',\n",
    "               'IPSL-IPSL-CM5A-MR' : 'IPSL-CM5A-MR',\n",
    "               'MIROC-MIROC5' : 'MIROC5',\n",
    "               'MOHC-HadGEM2-ES' : 'HadGEM2-ES',\n",
    "               'MPI-M-MPI-ESM-LR' : 'MPI-ESM-LR',\n",
    "               'MPI-M-MPI-ESM-MR' : 'MPI-ESM-MR',\n",
    "               'NCC-NorESM1-M' : 'NorESM1-M',\n",
    "               'NOAA-GFDL-GFDL-ESM2G' : 'GFDL-ESM2G',\n",
    "               'NOAA-GFDL-GFDL-ESM2M' : 'GFDL-ESM2M'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# extract subset of data for easier handling\n",
    "for varnm in mdl_list.keys():\n",
    "    ml = mdl_list[varnm]\n",
    "    \n",
    "    for fp in ml:\n",
    "        mdl = \"_\".join([abridge_gcm[fp.split(\"/\")[-3]]] + fp.split(\"/\")[-2:])\n",
    "        print(mdl + \" (\"+str(ml.index(fp)+1)+\"/\"+str(len(ml))+\")\")\n",
    "        \n",
    "        # something wrong with time bounds in this one, can't open the files\n",
    "        if mdl in ['HadGEM2-ES_r1i1p1_RegCM4-3']: continue\n",
    "        \n",
    "        fl = sorted(glob.glob(fp+\"/\"+varnm+\"/\"+varnm+\"_*.nc\"))\n",
    "        print(\"  \"+varnm+\" (\"+str(len(fl))+\") \", end = \"\")\n",
    "        \n",
    "        for fnm in fl:\n",
    "            print(\".\", end = \"\")\n",
    "            new_fnm = out_path+\"_\".join([varnm, fnm.split(\"_\")[2], mdl, fnm.split(\"_\")[-1]])\n",
    "            \n",
    "            # skip if file has already been processed\n",
    "            if os.path.exists(new_fnm): continue\n",
    "            \n",
    "            # load data, convert to correct units\n",
    "            da = xr.open_dataset(fnm)[varnm]\n",
    "            da = convert_units_to(da, units[varnm])\n",
    "            if \"height\" in da.coords: da.reset_coords(\"height\", drop = True)  # clean up unwanted extra coordinates\n",
    "                \n",
    "            # identify primary coordinates\n",
    "            if \"rlon\" in da.dims:\n",
    "                xdim, ydim = [\"rlat\", \"rlon\"]\n",
    "            elif \"x\" in da.dims:\n",
    "                xdim, ydim = [\"x\", \"y\"]\n",
    "            else:\n",
    "                print(da.dims)\n",
    "                continue\n",
    "            \n",
    "            # cut out smaller region & save as temp file\n",
    "            box = np.logical_and(np.logical_and(da.lon >= Xn, da.lon <= Xx), np.logical_and(da.lat >= Yn, da.lat <= Yx))\n",
    "            box = box.where(box == 1).dropna(xdim, \"all\").dropna(ydim, \"all\")\n",
    "            da = da.sel({xdim : box[xdim], ydim : box[ydim]})\n",
    "            da.to_netcdf(new_fnm)\n",
    "            \n",
    "            print(\".\", end = \"\")\n",
    "        print(\"\")\n",
    "    clear_output(wait = False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wwa",
   "language": "python",
   "name": "wwa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
