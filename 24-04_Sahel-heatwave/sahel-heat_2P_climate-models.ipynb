{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec669fc-8cef-454e-8fab-67d845482c51",
   "metadata": {},
   "source": [
    "# CMIP6 on JASMIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521fa21-2e0a-4c69-81b0-f537a4f61a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import regionmask\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/users/clairb/00_notebooks/24-04_sahel-heat\")\n",
    "\n",
    "import dask; dask.config.set(**{'array.slicing.split_large_chunks': True})\n",
    "\n",
    "# broader region for spatial pattern\n",
    "Xn, Xx, Yn, Yx = [-18,52,0,35]\n",
    "\n",
    "# region for West Africa time series analysis\n",
    "xn,xx,yn,yx = [-10,20,10,17]\n",
    "box_str = \"_\".join([str(i) for i in [xn,xx,yn,yx]])\n",
    "\n",
    "# shapefile\n",
    "sf = gpd.read_file(\"sf_malibf\")\n",
    "sf_str = \"malibf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd9a30-73f3-4ca8-917e-894330f36d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_lon(ds):\n",
    "    \n",
    "    # method to wrap longitude from (0,360) to (-180,180)\n",
    "    \n",
    "    if \"longitude\" in ds.coords:\n",
    "        lon = \"longitude\"\n",
    "        lat = \"latitude\"\n",
    "    elif \"lon\" in ds.coords:\n",
    "        lon = \"lon\"\n",
    "        lat = \"lat\"\n",
    "    else: \n",
    "        # can only wrap longitude\n",
    "        return ds\n",
    "    \n",
    "    if ds[lon].max() > 180:\n",
    "        ds[lon] = (ds[lon].dims, (((ds[lon].values + 180) % 360) - 180), ds[lon].attrs)\n",
    "        \n",
    "    if lon in ds.dims:\n",
    "        ds = ds.reindex({ lon : np.sort(ds[lon]) })\n",
    "        ds = ds.reindex({ lat : np.sort(ds[lat]) })\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396c611-4dde-4ed2-b210-315ebc8634ee",
   "metadata": {},
   "source": [
    "## Identify models with both historical & SSP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3606c2-a8c3-4dd5-9b57-769d0bd92c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "varnm = \"tasmax\"\n",
    "\n",
    "# list all models with available historical data\n",
    "fl_hist = glob.glob('/badc/cmip6/data/CMIP6/CMIP/*/*/historical/*/day/'+varnm)\n",
    "mdl_hist = [re.sub(\"_historical\", \"\", \"_\".join(fnm.split(\"/\")[6:10])) for fnm in fl_hist]\n",
    "\n",
    "# list all models with available SSP585 data\n",
    "fl_ssp = glob.glob('/badc/cmip6/data/CMIP6/ScenarioMIP/*/*/ssp585/*/day/'+varnm)\n",
    "mdl_ssp = [re.sub(\"_ssp585\", \"\", \"_\".join(fnm.split(\"/\")[6:10])) for fnm in fl_ssp]\n",
    "\n",
    "# list all model variants for which both historical & SSP are available\n",
    "model_vars = sorted([m for m in mdl_hist if m in mdl_ssp])\n",
    "\n",
    "# identify unique models & get first ensemble member for each\n",
    "models = list(set([\"_\".join(m.split(\"_\")[:2]) for m in model_vars]))\n",
    "models = [[v for v in model_vars if m in v][0] for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e15bc-eb44-4f68-b132-28522b47fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut out time series & spatial pattern for individual files\n",
    "for mdl in models:\n",
    "\n",
    "    print(mdl, end = \"\")\n",
    "    inst, gcm, em = mdl.split(\"_\")\n",
    "\n",
    "    sp_fnm = \"spatial/\"+varnm+\"_\"+mdl+\"_\"+box_str+\"_spatial-monthly.nc\"\n",
    "    box_fnm = \"daily/\"+varnm+\"_\"+mdl+\"_\"+box_str+\"_daily.nc\"\n",
    "    sf_fnm = \"daily/\"+varnm+\"_\"+mdl+\"_\"+sf_str+\"_daily.nc\"\n",
    "\n",
    "    # if os.path.exists(sp_fnm) and os.path.exists(box_fnm) and os.path.exists(sf_fnm): \n",
    "    if os.path.exists(sf_fnm): \n",
    "        print(\"Already processed\")\n",
    "        continue\n",
    "\n",
    "    # list all relevant files (not including anything past 2050 at the moment)\n",
    "    fl_h = glob.glob(\"/badc/cmip6/data/CMIP6/CMIP/\"+inst+\"/\"+gcm+\"/historical/\"+em+\"/day/\"+varnm+\"/*/latest/*.nc\")\n",
    "    fl_s = glob.glob(\"/badc/cmip6/data/CMIP6/ScenarioMIP/\"+inst+\"/\"+gcm+\"/ssp585/\"+em+\"/day/\"+varnm+\"/*/latest/*.nc\")\n",
    "    fl_s = [fnm for fnm in fl_s if int(fnm[-20:-16]) <= 2050]\n",
    "\n",
    "    fl = fl_h + fl_s\n",
    "    if(len(fl) == 0): continue\n",
    "\n",
    "    for fnm in fl:\n",
    "        \n",
    "        # load the data\n",
    "        da = wrap_lon(xr.open_dataset(fnm)).reset_coords(drop = True)[varnm].sel(lon = slice(Xn,Xx), lat = slice(Yn,Yx))\n",
    "    \n",
    "        # can't convert units or calendar on Jasmin so will have to handle that later\n",
    "\n",
    "        # # monthly spatial pattern\n",
    "        # sp = da.groupby(\"time.month\").mean()\n",
    "        # sp.to_netcdf(\"cmip6/\"+re.sub(\"day\", \"spatial\", fnm.split(\"/\")[-1]))\n",
    "\n",
    "        # # get daily time series over rectangular region\n",
    "        # ts_box = da.sel(lon = slice(xn,xx), lat = slice(yn,yx)).mean([\"lat\", \"lon\"])\n",
    "        # ts_box.to_netcdf(\"cmip6/\"+re.sub(\"day\", \"daily-box\", fnm.split(\"/\")[-1]))\n",
    "\n",
    "        # get daily time series over shapefile region\n",
    "        rm = regionmask.mask_3D_geopandas(sf, da.lon, da.lat).sum(\"region\")\n",
    "        ts_sf = da.where(rm == 1).mean([\"lat\", \"lon\"])\n",
    "        ts_sf.to_netcdf(\"cmip6/\"+re.sub(\"day\", \"daily-sf\", fnm.split(\"/\")[-1]))\n",
    "\n",
    "        print(\".\", end = \"\")\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wwa]",
   "language": "python",
   "name": "conda-env-wwa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
