{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..'); from wwa import *\n",
    "\n",
    "xn,xx,yn,yx = [27,41,-13,2]\n",
    "rxn,rxx,ryn,ryx = [34.5,38,-2,1]\n",
    "mapproj = cartopy.crs.PlateCarree()\n",
    "\n",
    "sf = gpd.read_file(\"sf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lv = gpd.read_file(\"sf_lvictoria\")\n",
    "sf_lt = gpd.read_file(\"sf_ltanganyika\")\n",
    "sf_tc = gpd.read_file(\"sf_tanzaniaCoast\")\n",
    "sf_ch = gpd.read_file(\"sf_centralHighlands\")\n",
    "sf_box = gpd.GeoDataFrame(pd.DataFrame(data = {\"region\" : [\"box\"]}, index = [0]), geometry = [Polygon(zip([rxn,rxn,rxx,rxx,rxn], [ryn,ryx,ryx,ryn,ryn]))], crs = \"EPSG:4326\")\n",
    "\n",
    "sf_vt = gpd.read_file(\"sf_lvictoriaTanganyika\")\n",
    "sf_org = gpd.read_file(\"sf\")\n",
    "\n",
    "sf_names = {\"lv\" : \"Lake Victoria basin\", \"lt\" : \"Lake Tanganyika basin\", \"tc\" : \"southeast Tanzania\",\n",
    "            \"ch\" : \"Central Highlands to coast\", \"box\" : \"Central Highlands\", \"vt\" : \"Lake Victoria & Tanganyika basins\", \"org\" : \"Tanzania/Burundi/SW Kenya\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HighResMIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data over the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = sorted(glob.glob(\"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/synda_Mariam/data/highresmip/*/pr/\"))\n",
    "outpath = \"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/eastAfrica_floods/highresmip/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mpath in ml:\n",
    "    \n",
    "    print(mpath.split(\"/\")[-3])\n",
    "    fl_hist = sorted(glob.glob(mpath+\"*present*[0-9].nc\"))\n",
    "    fl_fut = sorted(glob.glob(mpath+\"*future*[0-9].nc\"))\n",
    "\n",
    "    # filter file list to remove duplicated years\n",
    "    last_hist = fl_hist[-1][-11:-3]\n",
    "    fl_fut = [fnm for fnm in fl_fut if fnm[-20:-12] > last_hist]\n",
    "\n",
    "    new_fnm = outpath + \"pr_day_\"+\"_\".join(fl_hist[0].split(\"_\")[6:7]+fl_hist[0].split(\"_\")[-3:-1])+\".nc\"\n",
    "    \n",
    "    if os.path.exists(new_fnm): continue\n",
    "    da = xr.open_mfdataset(fl_hist + fl_fut).pr.sel(lon = slice(xn-2,xx+2), lat = slice(yn-2,yx+2))\n",
    "\n",
    "    da.to_netcdf(new_fnm)\n",
    "    \n",
    "clear_output(wait = False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series, spatial & seasonal patterns\n",
    "for fnm in glob.glob(outpath+\"*.nc\"):\n",
    "    \n",
    "    mdl = \"_\".join(fnm.split(\"_\")[-3:-1])\n",
    "    da = convert_units_to(xr.open_dataset(fnm).pr, \"mm/day\")\n",
    "    \n",
    "    if len(da.sel(time = slice(\"1990\",\"2020\")).time) == 0: continue\n",
    "    \n",
    "    # spatial pattern\n",
    "    sp = da.resample(time = \"QS-DEC\").sum().groupby(\"time.season\")[\"MAM\"].sel(time = slice(\"1990\", \"2020\")).mean(\"time\")\n",
    "    sp.to_netcdf(\"data/highresMIP/\"+re.sub(\"day\", \"spatial\", fnm.split(\"/\")[-1]))\n",
    "    \n",
    "    # daily time series\n",
    "    for sf_nm in list(sf_names.keys()):\n",
    "        sf = eval(\"sf_\"+sf_nm)\n",
    "        rm = regionmask.mask_geopandas(sf, da.lon, da.lat)\n",
    "        ts = da.where(rm == 0).mean([\"lat\", \"lon\"])\n",
    "    \n",
    "        # seasonal cycle\n",
    "        sc = ts.sel(time = slice(\"1990\",\"2020\")).groupby(\"time.dayofyear\").mean()\n",
    "        sc.to_netcdf(\"data/highresMIP/\"+re.sub(\"_day\", \"-\"+sf_nm+\"_seasonal-cycle\", fnm.split(\"/\")[-1]))\n",
    "    \n",
    "        # create time series for Climate Explorer\n",
    "        for ndays in [30]:\n",
    "\n",
    "            rxnday = ts.rolling(time = ndays).sum().resample(time = \"QS-DEC\").max().groupby(\"time.season\")[\"MAM\"]\n",
    "            rxnday = rxnday.assign_coords(time = rxnday.time.dt.year).rename(time = \"year\").to_dataframe()\n",
    "\n",
    "            csv_fnm = \"EA-floods_rx\"+str(ndays)+\"day-\"+sf_nm+\"_highresmip_\"+mdl\n",
    "            csv_fullpath = \"ts_highresmip/\"+csv_fnm+\".dat\"\n",
    "            if len(csv_fnm) > 61: print(\"! Filename too long: \", csv_fnm)\n",
    "\n",
    "            # create extra header lines for upload to Climate Explorer \n",
    "            str1 = \"# contact :: HighResMIP \"+mdl+\" MAM maxima of rx\"+str(ndays)+\"day - East Africa floods 2024, c.barnes22@imperial.ac.uk\"\n",
    "            str2 = \"# rx\"+str(ndays)+\"day [mm] March-May maximum of \"+str(ndays)+\"-day accumulated precipitation over \"+sf_names[sf_nm]+\" at \"+csv_fnm+\".dat\"\n",
    "            head = \"# year rx\"+str(ndays)+\"day\"\n",
    "\n",
    "            # make .dat file\n",
    "            ! echo \"$str1 \" > $csv_fullpath\n",
    "            ! echo \"$str2\" >> $csv_fullpath\n",
    "            ! echo \"$head\" >> $csv_fullpath\n",
    "            rxnday.to_csv(csv_fullpath, sep = \" \", mode = \"a\", header = False)\n",
    "\n",
    "            clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded observational products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = \"chirps\"; da = wrap_lon(xr.open_dataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/eastAfrica_floods/precip_chirps_1981-2024_EA.nc\")).precip.rename(\"pr\", longitude = \"lon\", latitude = \"lat\")\n",
    "# ds = \"tamsat\"; da = wrap_lon(xr.open_dataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/eastAfrica_floods/precip_tamsat_1983-2024_EA.nc\")).rfe.rename(\"pr\")\n",
    "ds = \"mswep\"; da = wrap_lon(xr.open_mfdataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/eastAfrica_floods/MSWEP/mswep_EA_*.nc\")).precipitation.rename(\"pr\")\n",
    "# ds = \"cpc\"; da = wrap_lon(xr.open_mfdataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/live/data/cpc/precip*.nc\")).precip.rename(\"pr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily time series from shapefiles\n",
    "for sf_nm in list(sf_names.keys()):\n",
    "    sf = eval(\"sf_\"+sf_nm)\n",
    "    rm = regionmask.mask_geopandas(sf, da.lon, da.lat)\n",
    "    ts = da.where(rm == 0).mean([\"lat\", \"lon\"])\n",
    "    ts.to_netcdf(\"data/daily-ts_\"+sf_nm+\"_\"+ds+\".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridded n-day seasonal maxima\n",
    "for ndays in [30, 60]:\n",
    "    da = da.sel(lon = slice(xn,xx), lat = slice(yn,yx))\n",
    "    rxnday = da.rolling(time = ndays, center = False).sum().resample(time = \"QS-DEC\").max().groupby(\"time.season\")[\"MAM\"]\n",
    "    rxnday.to_netcdf(\"data/rx\"+str(ndays)+\"day-MAM_gridded_\"+ds+\".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series for climate explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"cpc\", \"mswep\", \"chirps\", \"tamsat\"]\n",
    "for ndays in [30]:\n",
    "    for region in list(sf_names.keys()):\n",
    "        for ds in datasets:\n",
    "\n",
    "            ts = xr.open_dataset(\"data/daily-ts_\"+region+\"_\"+ds+\".nc\").pr\n",
    "            ts = ts.rolling(time = ndays, center = False).sum().resample(time = \"QS-DEC\").max().groupby(\"time.season\")[\"MAM\"]\n",
    "            ts = ts.assign_coords(time = ts.time.dt.year).rename(time = \"year\").to_dataframe()\n",
    "\n",
    "            csv_fnm = \"EA-floods_rx\"+str(ndays)+\"day_obs-\"+region+\"_\"+ds\n",
    "            csv_fullpath = \"ts_obs/\"+csv_fnm+\".dat\"\n",
    "\n",
    "            if len(csv_fnm) > 61: print(\"! Filename too long: \", csv_fnm)\n",
    "                \n",
    "            rnm = sf_names[region]\n",
    "\n",
    "            # create extra header lines for upload to Climate Explorer \n",
    "            str1 = \"# contact :: \"+ds.upper()+\" MAM maxima of rx\"+str(ndays)+\"day averaged over \"+rnm+\" - East Africa floods 2024, c.barnes22@imperial.ac.uk\"\n",
    "            str2 = \"# rx\"+str(ndays)+\"day [mm] March-May maxima of \"+str(ndays)+\"-day accumulated precipitation at \"+csv_fnm+\".dat\"\n",
    "            head = \"# year rx\"+str(ndays)+\"day\"\n",
    "\n",
    "            # make .dat file\n",
    "            ! echo \"$str1 \" > $csv_fullpath\n",
    "            ! echo \"$str2\" >> $csv_fullpath\n",
    "            ! echo \"$head\" >> $csv_fullpath\n",
    "            ts.to_csv(csv_fullpath, sep = \" \", mode = \"a\", header = False)\n",
    "\n",
    "            clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAM climatology 1990-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = \"chirps\"; da = wrap_lon(xr.open_dataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/eastAfrica_floods/precip_chirps_1981-2024_EA.nc\")).precip.rename(\"pr\", longitude = \"lon\", latitude = \"lat\")\n",
    "# ds = \"tamsat\"; da = wrap_lon(xr.open_dataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/eastAfrica_floods/precip_tamsat_1983-2024_EA.nc\")).rfe.rename(\"pr\")\n",
    "# ds = \"mswep\"; da = wrap_lon(xr.open_mfdataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/eastAfrica_floods/MSWEP/mswep_EA_*.nc\")).precipitation.rename(\"pr\")\n",
    "ds = \"cpc\"; da = wrap_lon(xr.open_mfdataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/live/data/cpc/precip*.nc\")).precip.rename(\"pr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = da.resample(time = \"QS-DEC\").sum().groupby(\"time.season\")[\"MAM\"].sel(time = slice(\"1990\", \"2020\")).mean(\"time\")\n",
    "clim = clim.where(clim > 0)\n",
    "clim.to_netcdf(\"data/mam-climatology_\"+ds+\".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten gridded data for trend fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridded n-day seasonal maxima over study region only\n",
    "ndays = 30\n",
    "for ds in [\"chirps\", \"cpc\", \"mswep\", \"tamsat\"][1:]:\n",
    "    \n",
    "    da = xr.open_dataset(\"data/rx\"+str(ndays)+\"day-MAM_gridded_\"+ds+\".nc\").pr\n",
    "    da = da.assign_coords(time = da.time.dt.year).rename(time = \"year\")\n",
    "    \n",
    "    if ds in [\"mswep\"]:\n",
    "        # mask out the sea\n",
    "        rm = regionmask.defined_regions.natural_earth_v5_0_0.land_10.mask(da.lon, da.lat)\n",
    "        da = da.where(rm == 0)\n",
    "\n",
    "    # save the map for easier reconstruction later\n",
    "    da.mean(\"year\").to_netcdf(\"data/map-tmplt_\"+ds+\".nc\")\n",
    "    \n",
    "    # flatten & save as .csv for transfer to R\n",
    "    da_df = da.stack(xy = [\"lat\", \"lon\"]).dropna(\"xy\", \"all\").to_pandas()\n",
    "    \n",
    "    if da_df.shape[1] > 2500:\n",
    "        for i in range(int(np.ceil(da_df.shape[1] / 2500))):\n",
    "            da_df.iloc[:,slice(i*2500,(i+1)*2500)].to_csv(\"data/flattened/rx\"+str(ndays)+\"days-flattened_\"+ds+\"_\"+str(i+1).rjust(2,\"0\")+\".csv\")\n",
    "    else:\n",
    "        da_df.to_csv(\"data/flattened/rx\"+str(ndays)+\"days-flattened_\"+ds+\".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape dataframe into maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category = FutureWarning) # otherwise there will be a LOT of warnings\n",
    "\n",
    "def vec2map(x, mask):\n",
    "    \n",
    "    # reconstruct vector into map\n",
    "    # create an empty map with NA in same cells as masks\n",
    "    arr = mask.where(np.isnan(mask), 0)\n",
    "    \n",
    "    # get coordinates of non-empty cells\n",
    "    px = np.argwhere(~np.isnan(mask.values))\n",
    "    \n",
    "    # Transfer vector values into non-empty cells in array\n",
    "    if len(px) == len(x):\n",
    "        for i in list(range(len(px))): arr[px[i,0], px[i,1]] = x[i]\n",
    "        return arr\n",
    "    else:\n",
    "        print(str(len(x))+\" values, but \"+str(len(px))+\" cells\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndays = 30\n",
    "datasets = [\"tamsat\", \"chirps\", \"cpc\", \"mswep\"]\n",
    "for ds in datasets:\n",
    "    \n",
    "    new_fnm = \"res/res-gridded_rx\"+str(ndays)+\"day_\"+ds+\".nc\"\n",
    "    if os.path.exists(new_fnm): continue\n",
    "    \n",
    "    # load map to be used to reshape\n",
    "    tmplt = xr.open_dataset(\"data/map-tmplt_\"+ds+\".nc\").pr\n",
    "    \n",
    "    df = merge_byindex([pd.read_csv(fnm, index_col = 0) for fnm in sorted(glob.glob(\"data/gridded-res/rx\"+str(ndays)+\"day*_\"+ds+\"*.csv\"))])\n",
    "    mdl_res = xr.merge([vec2map(df.loc[r], tmplt).rename(r) for r in df.index])\n",
    "    mdl_res.to_netcdf(new_fnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAM IOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iod = decode_times(xr.open_dataset(\"data/idmi_ersst.nc\", decode_times = False))[\"diff\"].rename(\"IOD\")\n",
    "\n",
    "iod_mam = iod.resample(time = \"QS-DEC\").mean().groupby(\"time.season\")[\"MAM\"]\n",
    "iod_mam = iod_mam.assign_coords(time = iod_mam.time.dt.year).rename(time = \"year\").to_dataframe()\n",
    "ts = iod_mam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_fnm = \"EA-floods_iod-mam_obs_ersst\"\n",
    "csv_fullpath = \"ts/\"+csv_fnm+\".dat\"\n",
    "\n",
    "if len(csv_fnm) > 61: print(\"! Filename too long: \", csv_fnm)\n",
    "\n",
    "# create extra header lines for upload to Climate Explorer \n",
    "str1 = \"# contact :: MAM IOD (ERSST) - East Africa floods 2024, c.barnes22@imperial.ac.uk\"\n",
    "str2 = \"# iod [degC] March-May mean of IOD at \"+csv_fnm+\".dat\"\n",
    "head = \"# year iod\"\n",
    "\n",
    "# make .dat file\n",
    "! echo \"$str1 \" > $csv_fullpath\n",
    "! echo \"$str2\" >> $csv_fullpath\n",
    "! echo \"$head\" >> $csv_fullpath\n",
    "iod_mam.to_csv(csv_fullpath, sep = \" \", mode = \"a\", header = False)\n",
    "\n",
    "clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DJF detrended Nino3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nino = xr.open_dataset(\"../10_misc/detrended_nino34/ersst_nino34_detrended.nc\").nino34\n",
    "nino_djf = nino.resample(time = \"QS-DEC\").mean().groupby(\"time.season\")[\"DJF\"]\n",
    "nino_djf = nino_djf.assign_coords(time = nino_djf.time.dt.year + 1).rename(time = \"year\").to_dataframe()\n",
    "ts = nino_djf\n",
    "\n",
    "csv_fnm = \"EA-floods_nino-djf_obs_ersst\"\n",
    "csv_fullpath = \"ts/\"+csv_fnm+\".dat\"\n",
    "\n",
    "if len(csv_fnm) > 61: print(\"! Filename too long: \", csv_fnm)\n",
    "\n",
    "# create extra header lines for upload to Climate Explorer \n",
    "str1 = \"# contact :: DJF detrended Nino3.4 (ERSST) - East Africa floods 2024, c.barnes22@imperial.ac.uk\"\n",
    "str2 = \"# nino [degC] December-February mean of Nino3.4 detrended by subtracting mean of tropical SSTs at \"+csv_fnm+\".dat\"\n",
    "head = \"# year nino\"\n",
    "\n",
    "# make .dat file\n",
    "! echo \"$str1 \" > $csv_fullpath\n",
    "! echo \"$str2\" >> $csv_fullpath\n",
    "! echo \"$head\" >> $csv_fullpath\n",
    "ts.to_csv(csv_fullpath, sep = \" \", mode = \"a\", header = False)\n",
    "\n",
    "clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wwa]",
   "language": "python",
   "name": "conda-env-wwa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
