{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..'); from wwa import *\n",
    "\n",
    "xn,xx,yn,yx = [27,41,-13,2]\n",
    "mapproj = cartopy.crs.PlateCarree()\n",
    "\n",
    "sf = gpd.read_file(\"sf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HighResMIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data over the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = sorted(glob.glob(\"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/synda_Mariam/data/highresmip/*/pr/\"))\n",
    "outpath = \"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/eastAfrica_floods/highresmip/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mpath in ml:\n",
    "    \n",
    "    print(mpath.split(\"/\")[-3])\n",
    "    fl_hist = sorted(glob.glob(mpath+\"*present*[0-9].nc\"))\n",
    "    fl_fut = sorted(glob.glob(mpath+\"*future*[0-9].nc\"))\n",
    "\n",
    "    # filter file list to remove duplicated years\n",
    "    last_hist = fl_hist[-1][-11:-3]\n",
    "    fl_fut = [fnm for fnm in fl_fut if fnm[-20:-12] > last_hist]\n",
    "\n",
    "    new_fnm = outpath + \"pr_day_\"+\"_\".join(fl_hist[0].split(\"_\")[6:7]+fl_hist[0].split(\"_\")[-3:-1])+\".nc\"\n",
    "    \n",
    "    if os.path.exists(new_fnm): continue\n",
    "    da = xr.open_mfdataset(fl_hist + fl_fut).pr.sel(lon = slice(xn,xx), lat = slice(yn,yx))\n",
    "\n",
    "    da.to_netcdf(new_fnm)\n",
    "    \n",
    "clear_output(wait = False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fnm in glob.glob(outpath+\"*.nc\"):\n",
    "    \n",
    "    mdl = \"_\".join(fnm.split(\"_\")[-3:-1])\n",
    "    da = convert_units_to(xr.open_dataset(fnm).pr, \"mm/day\")\n",
    "    \n",
    "    if len(da.sel(time = slice(\"1990\",\"2020\")).time) == 0: continue\n",
    "    \n",
    "    # spatial pattern\n",
    "    sp = da.resample(time = \"QS-DEC\").sum().groupby(\"time.season\")[\"MAM\"].sel(time = slice(\"1990\", \"2020\")).mean(\"time\")\n",
    "    sp.to_netcdf(\"data/highresMIP/\"+re.sub(\"day\", \"spatial\", fnm.split(\"/\")[-1]))\n",
    "    \n",
    "    # daily time series\n",
    "    rm = regionmask.mask_geopandas(sf, da.lon, da.lat)\n",
    "    ts = da.where(rm == 0).mean([\"lat\", \"lon\"])\n",
    "    \n",
    "    # seasonal cycle\n",
    "    sc = ts.sel(time = slice(\"1990\",\"2020\")).groupby(\"time.dayofyear\").mean()\n",
    "    sc.to_netcdf(\"data/highresMIP/\"+re.sub(\"day\", \"seasonal-cycle\", fnm.split(\"/\")[-1]))\n",
    "    \n",
    "    # create time series for Climate Explorer\n",
    "    for ndays in [30,60]:\n",
    "        \n",
    "        rxnday = ts.rolling(time = ndays).sum().resample(time = \"QS-DEC\").max().groupby(\"time.season\")[\"MAM\"]\n",
    "        rxnday = rxnday.assign_coords(time = rxnday.time.dt.year).rename(time = \"year\").to_dataframe()\n",
    "        \n",
    "        csv_fnm = \"EA-floods_rx\"+str(ndays)+\"day_highresmip_\"+mdl\n",
    "        csv_fullpath = \"ts/\"+csv_fnm+\".dat\"\n",
    "        if len(csv_fnm) > 61: print(\"! Filename too long: \", csv_fnm)\n",
    "            \n",
    "        # create extra header lines for upload to Climate Explorer \n",
    "        str1 = \"# contact :: HighResMIP \"+mdl+\" MAM maxima of rx\"+str(ndays)+\"day - East Africa floods 2024, c.barnes22@imperial.ac.uk\"\n",
    "        str2 = \"# rx\"+str(ndays)+\"day [mm] March-May maximum of \"+str(ndays)+\"-day accumulated precipitatio at \"+csv_fnm+\".dat\"\n",
    "        head = \"# year rx\"+str(ndays)+\"day\"\n",
    "\n",
    "        # make .dat file\n",
    "        ! echo \"$str1 \" > $csv_fullpath\n",
    "        ! echo \"$str2\" >> $csv_fullpath\n",
    "        ! echo \"$head\" >> $csv_fullpath\n",
    "        rxnday.to_csv(csv_fullpath, sep = \" \", mode = \"a\", header = False)\n",
    "\n",
    "        clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded observational products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = \"chirps\"; da = wrap_lon(xr.open_dataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/eastAfrica_floods/precip_chirps_1981-2024_EA.nc\")).precip.rename(\"pr\", longitude = \"lon\", latitude = \"lat\")\n",
    "# ds = \"tamsat\"; da = wrap_lon(xr.open_dataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/eastAfrica_floods/precip_tamsat_1983-2024_EA.nc\")).rfe.rename(\"pr\")\n",
    "# ds = \"mswep\"; da = wrap_lon(xr.open_mfdataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/eastAfrica_floods/MSWEP/mswep_EA_*.nc\")).precipitation.rename(\"pr\")\n",
    "ds = \"cpc\"; da = wrap_lon(xr.open_mfdataset(\"/rds/general/user/cb2714/home/00_WWA_project_folder/live/data/cpc/precip*.nc\")).precip.rename(\"pr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily time series\n",
    "rm = regionmask.mask_geopandas(sf, da.lon, da.lat)\n",
    "ts = da.where(rm == 0).mean([\"lat\", \"lon\"])\n",
    "ts.to_netcdf(\"data/daily-ts_pr_\"+ds+\".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/cb2714/home/anaconda3/envs/wwa/lib/python3.10/site-packages/dask/array/reductions.py:640: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmax(x_chunk, axis=axis, keepdims=keepdims)\n",
      "/rds/general/user/cb2714/home/anaconda3/envs/wwa/lib/python3.10/site-packages/dask/array/reductions.py:640: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.nanmax(x_chunk, axis=axis, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# gridded n-day seasonal maximua over study region only\n",
    "for ndays in [30, 60]:\n",
    "    da = da.sel(lon = slice(xn,xx), lat = slice(yn,yx))\n",
    "    rxnday = da.rolling(time = ndays, center = False).sum().resample(time = \"QS-DEC\").max().groupby(\"time.season\")[\"MAM\"]\n",
    "    rxnday.to_netcdf(\"data/rx\"+str(ndays)+\"day-MAM_gridded_\"+ds+\".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series for climate explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"cpc\", \"mswep\", \"chirps\", \"tamsat\"]\n",
    "for ndays in [30,60]:\n",
    "    for ds in datasets:\n",
    "\n",
    "        ts = xr.open_dataset(\"data/daily-ts_pr_\"+ds+\".nc\").pr\n",
    "        ts = ts.rolling(time = ndays, center = False).sum().resample(time = \"QS-JAN\").max().groupby(\"time.season\")[\"MAM\"]\n",
    "        ts = ts.assign_coords(time = ts.time.dt.year).rename(time = \"year\").to_dataframe()\n",
    "\n",
    "        csv_fnm = \"EA-floods_rx\"+str(ndays)+\"day_obs_\"+ds\n",
    "        csv_fullpath = \"ts/\"+csv_fnm+\".dat\"\n",
    "\n",
    "        if len(csv_fnm) > 61: print(\"! Filename too long: \", csv_fnm)\n",
    "\n",
    "        # create extra header lines for upload to Climate Explorer \n",
    "        str1 = \"# contact :: \"+ds.upper()+\" MAM maxima of rx\"+str(ndays)+\"day - East Africa floods 2024, c.barnes22@imperial.ac.uk\"\n",
    "        str2 = \"# rx\"+str(ndays)+\"day [mm] March-May maximum of \"+str(ndays)+\"-day accumulated precipitatio at \"+csv_fnm+\".dat\"\n",
    "        head = \"# year rx\"+str(ndays)+\"day\"\n",
    "\n",
    "        # make .dat file\n",
    "        ! echo \"$str1 \" > $csv_fullpath\n",
    "        ! echo \"$str2\" >> $csv_fullpath\n",
    "        ! echo \"$head\" >> $csv_fullpath\n",
    "        ts.to_csv(csv_fullpath, sep = \" \", mode = \"a\", header = False)\n",
    "\n",
    "        clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wwa]",
   "language": "python",
   "name": "conda-env-wwa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
