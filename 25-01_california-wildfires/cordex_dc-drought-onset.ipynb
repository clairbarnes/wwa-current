{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "from matplotlib import pyplot as plt\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.534155716301562 35.51573667175686\n",
      "-121.45457486710173 -115.19969953245605\n"
     ]
    }
   ],
   "source": [
    "gdf = gpd.read_file(\"sf_socal-baja/\")\n",
    "gdf = gdf.to_crs(crs = \"EPSG:4326\")\n",
    "gdf = gdf[gdf.US_L3CODE == '85']\n",
    "gdf = gdf[gdf.Shape_Area == gdf.Shape_Area.max()]\n",
    "\n",
    "bbox = gdf.total_bounds\n",
    "latmin = bbox[1] - 1\n",
    "latmax = bbox[3] + 1\n",
    "lonmin = bbox[0] - 1\n",
    "lonmax = bbox[2] + 1\n",
    "\n",
    "print(latmin, latmax)\n",
    "print(lonmin, lonmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSR timeseries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob('/rds/general/user/cb2714/projects/wwa/ephemeral/'+\n",
    "                  'cali-wildfires/cordex-fwi/DSR*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    dsr = xr.open_dataset(path)['dsr']\n",
    "    dsr = dsr.rio.write_crs(\"EPSG:4326\")\n",
    "    dsr = dsr.rio.clip(gdf.geometry.values, gdf.crs, all_touched = True)\n",
    "\n",
    "    gdf = gpd.read_file(\"sf_socal-baja/\")\n",
    "    gdf = gdf.to_crs(crs = \"EPSG:4326\")\n",
    "    gdf = gdf[gdf.US_L3CODE == '85']\n",
    "    gdf = gdf[gdf.Shape_Area == gdf.Shape_Area.max()]\n",
    "\n",
    "    lats = dsr.latitude.data\n",
    "    lons = dsr.longitude.data\n",
    "\n",
    "    # Testing all widths are the same:\n",
    "    assert len(set(lats[1:] - lats[:-1])) == 1\n",
    "    assert len(set(lons[1:] - lons[:-1])) == 1\n",
    "\n",
    "    lat_width = np.abs(lats[1] - lats[0]) / 2\n",
    "    lon_width = np.abs(lons[1] - lons[0]) / 2\n",
    "\n",
    "    area_weights = np.zeros_like(dsr[0,:,:])\n",
    "    for i,lat in enumerate(lats):\n",
    "        for j,lon in enumerate(lons):\n",
    "            cell = Polygon([(lon + lon_width, lat + lat_width),\n",
    "                            (lon - lon_width, lat + lat_width),\n",
    "                            (lon - lon_width, lat - lat_width),\n",
    "                            (lon + lon_width, lat - lat_width)])\n",
    "            area_weights[i,j] = cell.intersection(gdf.geometry).area / cell.area\n",
    "\n",
    "    weighted_dsr = dsr * area_weights\n",
    "\n",
    "    data = weighted_dsr.rolling(time = 1).mean()\n",
    "    data = data.mean(dim = ['latitude','longitude'])\n",
    "    data = data.resample(time = 'M').max()\n",
    "    d1 = data[11::12]\n",
    "    d2 = data[12::12]\n",
    "    d2 = d2.sel(time = d2.time.dt.year >= d1.time.dt.year.min()+1)\n",
    "    d1 = d1.sel(time = d1.time.dt.year <= d2.time.dt.year.max()-1)\n",
    "    d1.data = np.max(np.array([d1.data,d2.data]), axis = 0)\n",
    "    outpath = 'cordex/DSR_1day_DJ_' + path.split('/')[-1][4:-3] + '.csv'\n",
    "    pd.DataFrame(d1.to_pandas(), columns = ['DJ_DSR_1day']).to_csv(outpath)\n",
    "\n",
    "    data = weighted_dsr.rolling(time = 2).mean()\n",
    "    data = data.mean(dim = ['latitude','longitude'])\n",
    "    data = data.resample(time = 'M').max()\n",
    "    d1 = data[11::12]\n",
    "    d2 = data[12::12]\n",
    "    d2 = d2.sel(time = d2.time.dt.year >= d1.time.dt.year.min()+1)\n",
    "    d1 = d1.sel(time = d1.time.dt.year <= d2.time.dt.year.max()-1)\n",
    "    d1.data = np.max(np.array([d1.data,d2.data]), axis = 0)\n",
    "    outpath = 'cordex/DSR_2day_DJ_' + path.split('/')[-1][4:-3] + '.csv'\n",
    "    pd.DataFrame(d1.to_pandas(), columns = ['DJ_DSR_2day']).to_csv(outpath)\n",
    "\n",
    "    data = weighted_dsr.rolling(time = 3).mean()\n",
    "    data = data.mean(dim = ['latitude','longitude'])\n",
    "    data = data.resample(time = 'M').max()\n",
    "    d1 = data[11::12]\n",
    "    d2 = data[12::12]\n",
    "    d2 = d2.sel(time = d2.time.dt.year >= d1.time.dt.year.min()+1)\n",
    "    d1 = d1.sel(time = d1.time.dt.year <= d2.time.dt.year.max()-1)\n",
    "    d1.data = np.max(np.array([d1.data,d2.data]), axis = 0)\n",
    "    outpath = 'cordex/DSR_3day_DJ_' + path.split('/')[-1][4:-3] + '.csv'\n",
    "    pd.DataFrame(d1.to_pandas(), columns = ['DJ_DSR_3day']).to_csv(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob('/rds/general/user/cb2714/projects/wwa/ephemeral/'+\n",
    "                  'cali-wildfires/cordex-fwi/FWI*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 26\n",
      "2 of 26\n",
      "3 of 26\n",
      "4 of 26\n",
      "5 of 26\n",
      "6 of 26\n",
      "7 of 26\n",
      "8 of 26\n",
      "9 of 26\n",
      "10 of 26\n",
      "11 of 26\n",
      "12 of 26\n",
      "13 of 26\n",
      "14 of 26\n",
      "15 of 26\n",
      "16 of 26\n",
      "17 of 26\n",
      "18 of 26\n",
      "19 of 26\n",
      "20 of 26\n",
      "21 of 26\n",
      "22 of 26\n",
      "23 of 26\n",
      "24 of 26\n",
      "25 of 26\n",
      "26 of 26\n"
     ]
    }
   ],
   "source": [
    "for k,path in enumerate(paths):\n",
    "    print(f'{k+1} of {len(paths)}')\n",
    "    fwi = xr.open_dataset(path)['fwi']\n",
    "    fwi = fwi.rio.write_crs(\"EPSG:4326\")\n",
    "    fwi = fwi.rio.clip(gdf.geometry.values, gdf.crs, all_touched = True)\n",
    "\n",
    "    gdf = gpd.read_file('/rds/general/user/cb2714/home/wwa_project/la/shapefiles/'+\n",
    "                        'us_eco_l3.shp')\n",
    "    gdf = gdf.to_crs(crs = \"EPSG:4326\")\n",
    "    gdf = gdf[gdf.US_L3CODE == '85']\n",
    "    gdf = gdf[gdf.Shape_Area == gdf.Shape_Area.max()]\n",
    "\n",
    "    lats = fwi.latitude.data\n",
    "    lons = fwi.longitude.data\n",
    "\n",
    "    # Testing all widths are the same:\n",
    "    assert len(set(lats[1:] - lats[:-1])) == 1\n",
    "    assert len(set(lons[1:] - lons[:-1])) == 1\n",
    "\n",
    "    lat_width = np.abs(lats[1] - lats[0]) / 2\n",
    "    lon_width = np.abs(lons[1] - lons[0]) / 2\n",
    "\n",
    "    area_weights = np.zeros_like(fwi[0,:,:])\n",
    "    for i,lat in enumerate(lats):\n",
    "        for j,lon in enumerate(lons):\n",
    "            cell = Polygon([(lon + lon_width, lat + lat_width),\n",
    "                            (lon - lon_width, lat + lat_width),\n",
    "                            (lon - lon_width, lat - lat_width),\n",
    "                            (lon + lon_width, lat - lat_width)])\n",
    "            area_weights[i,j] = cell.intersection(gdf.geometry).area / cell.area\n",
    "\n",
    "    weighted_fwi = fwi * area_weights\n",
    "\n",
    "    data = weighted_fwi.rolling(time = 1).mean()\n",
    "    data = data.mean(dim = ['latitude','longitude'])\n",
    "    data = data.resample(time = 'M').max()\n",
    "    data = data.sel(time = data.time.dt.month == 1)\n",
    "\n",
    "    outpath = 'cordex/FWI_1day_J_' + path.split('/')[-1][4:-3] + '.csv'\n",
    "    pd.DataFrame(data.to_pandas(), columns = ['J_FWI_1day']).to_csv(outpath)\n",
    "    \n",
    "    pd.DataFrame(weighted_fwi.mean(dim = ['latitude','longitude']).to_pandas(),\n",
    "                 columns = ['fwi']).to_csv(\n",
    "        (f'/rds/general/user/cb2714/projects/wwa/ephemeral/'+\n",
    "         f'cali-wildfires/timeseries/daily_fwi_{path.split(\"/\")[-1][4:-3]}.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wwa_xesmf]",
   "language": "python",
   "name": "conda-env-wwa_xesmf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
